一.你们测试通过的标准是什么样的？
1、测试用例覆盖当前版本的所有需求。
2、中高级测试用例均已通过。
3、测试用例颗粒度达到十五条测试用例覆盖一条需求。
4、中高级bug修复完成且验证通过，未关闭的bug不超过占当前版本bug总数的5%。

二、如果项目周期是1个月，那么你们每项测试工作分别占用多长时间？
1、第一周进行需求评审，制定计划和方案，编写测试点。
2、第二周编写测试用例，进行用例评审，搭建测试环境。
3、第三周执行测试用例，冒烟测试，进行sit测试，sit测试通过。
4、第四周进行验收测试，回归测试。

三.编写测试计划要重点设计哪些内容。
    编写测试计划重点内容：测试范围、时间安排、工作人员、预估项目工作量、测试通过的标准、测试应交付的文档。
    测试经理制定测试计划最重要的是合理安排项目时间预估项目组的工作量，合理安排测试人员的工作，保证测试人员能在指定的时间内完成工作。
    测试经理还要划定测试范围，这个项目需不需要做性能、兼容性、自动化测试等。
关于角色和职责，测试通过的标准，应交付的文档，每个版本都差不多，按照模板完成即可。

四.你会哪些测试用例设计方法？
1、等价类划分法，例如：新增商品、注册等，我们可以找出有效等价类和无效等价类。
2、边界值分析，例如：输入框测试，条件是6-15位，测试6位，15位。测试5位，16位。
3、流程分析法，例如：电商系统的基本流程，从商品上架开始，消费者浏览商品，加入购物车，去结算、支付、商家发货、消费者确认收货等。
4、状态分析法，当一个业务流程状态非常多的时候我们就可以用状态分析法来覆盖每一个状态。
5、正交实验法，精简测试用例，比较适合做组合测试，兼容性测试，配置测试等。
6、错误推测法，通过对以往版本出现的错误，来分析新版本可能会出现的错误。

五、说一下你们之前项目的Bug管理流程
1、我在执行测试用例的时候发现bug，我们提交到bug管理系统里面。
2、经理看见我提交的bug之后判断是否是一个有效的bug，如果是有效的bug会指定给开发进行修改。
3、开发修改bug以后，测试人员发包，进行回归测试，验证bug是否已经被修复，如果bug没有修复，就把这个bug驳回，让开发重新修改，如果bug修复了我就把这个bug关闭。
4、当经理和开发都不认可这个bug的情况下，可以直接关闭。
5、如果这个bug是当前技术不能解决的，项目成员会讨论这个bug是不是可以挂起，以后在解决。

六、你们之前自动化测试用例占整个软件测试用例的多少比例？为什么？
1、自动化测试用例占整个软件测试用例的20%-25%，因为我们自动化测试用例只设计了冒烟测试用例和回归测试用例，和还有一些核心功能正向的测试用例。
2、自动化测试用例占整个软件测试用例的60%以上，因为我们这个软件已经迭代了2年多，每迭代一个版本，我们都花时间做自动化，目前已经有1500条自动化测试用例，除了新版本的需求需要人工测试，旧版本的一些功能都用自动化测试来做。

七、说一说缺陷分析怎么做
1、根据每天提交的bug，来判断bug是否呈收敛趋势
2、根据每个模块提交的bug，来判断每个模块上线的风险
3、通过bug引入的原因，来优化下一个版本的优化环节
4、根据每个模块bug分布严重程度，来判断开发提测的质量

八、发包
1、找开发把新的代码包发过来
2、通知测试组停止工作，开始发包
3、连接linux服务器，把新的代码包放入服务器中
4、停止tomcat服务
5、进入tomcat webabb文件夹内，把旧的代码包删除，把新的代码包放进去
6、启动tomcat服务
7、打开浏览器访问页面
8、执行冒烟测试用例
9、冒烟测试用例通过，发包成功，冒烟测试用例失败，回滚代码，发包失败。

九、什么样的项目，什么样的场景，适合做自动化？
1、不断有新的需求，版本迭代很快的，做自动化有收益
2、简单重复的功能适合做自动化，需要智力的需要人工测试
3、新版本的需求需要人工测试，旧版本已经稳定的功能需要自动化测试
4、自动化测试主要是验证这个软件可用，如果这个软件不稳定，就没有做自动化的必要了
5、软件界面稳定之后才能做自动化，软件界面经常更改的话，就不适合做自动化

十、搭建测试环境
1、找一个数据库和应用服务器的操作系统（windows centos）
2、找一个应用服务器（阿帕奇，唐模凯特）
3、找一个数据库（麦思可，奥睿科）
4、把代码包放入应用服务器里面
5、打开浏览器，访问网址

十一、强制等待与隐式等待有什么区别？
强制等待，是一个很直观的等待时间，设置多长时间，就等待多长时间
隐式等待，操作不受阻不会生效，一旦操作受阻时，会自动等待时间，超过设置的时间就会报错

十二、脚本怎么做断言？
先确定一个运行成功或者是失败的元素进行断言
1、通过判断元素是否存在来进行断言，元素存在断言成功，元素失败断言失败
2、设置一个预期结果，然后提取元素的文本或者是属性值，通过预期结果和实际结果进行比较判断断言是否成功

十三、封装函数的作用有哪些？
1、提高代码的维护性，例如：网站界面发生变化，这时我们只用修改参数即可
2、提高代码的复用性，例如：一些常用的操作，我们可以把它给封装起来，登录，注册这样的模块

十四、你做自动化测试时，封装了哪些内容？
我们把封装的函数放入public文件夹里面
工具模块：读写文件、正则表达式
操作模块：打开浏览器、切换窗口、鼠标移动、截图
业务模块：登录、注册、二级、三级菜单
数据模块：用户名、密码、网址

十五、说一下脚本报错的原因有哪些，以及怎么解决的（至少4种原因）
1、页面窗口发生了变化，脚本默认在原窗口进行操作，这时我们需要切换窗口
2、代码跑的太快，页面来不及响应，这时我们需要增加强制等待时间和隐式等待时间
3、表达式书写错误，导致元素定位不到，我们需要在浏览器页面上书写表达式，确定定位到元素之后在代码中运用
4、元素在框架内，我们需要切换框架来进行定位框架内的元素

十六、怎么查看tomcat的进程？
1、使用ps -ef|grep tomcat 查看tomcat的进程
2、使用netstat -anop|grep 端口号来查询 http：80 https：443

十七、怎么强制结束tomcat进程？
先使用ps -ef|grep tomcat 查看tomcat的进程 查看pid 然后用kill -9 加pid 结束进程

十八、怎么查看系统CPU和内存占用？
1、top可以实时查看系统的内存和cpu的占用
2、free详细的查看系统的内存和cpu的占用

十九、怎么查看日志？
可以用less分页查看日志，shift+g到最后一行，然后用？关键词开始搜索，还可以用tail -f 查看实时日志，一边操作软件一边查看日志

二十、查询语句的6个关键词和它的用法
select 显示字段 from 表 where 条件 group 分组字段 having 聚合函数 orderby 排序

二十一、你们的系统有多少张表，你常用的数据表有哪几张？
我们项目有60张表，包括用户信息表、商品信息表、订单表、

二十二、GET请求与POST请求的区别？
get请求参数放在url后面，限制长度比较短，安全性较差
post请求放在body里面，用的是jason格式，限制长度比较长，安全性比get请求高一个点

二十三、什么是持续集成？持续集成可以达到什么效果？
持续化集成 持续化交付
就是把开发一天所编写的代码集成到主干配置库里面，通过打包和发包的形式，做冒烟测试或者是回归测试，发送给测试部门，提高工作效率，发现bug。
持续化集成对于项目节奏比较快的团队比较适合，可以实现bug的日清日结，适合敏捷开发

二十四、Jenkins怎么用的？
1、安装jdk
2、打开命令行，输入java -jar 加jekins的路径 安装并启动jekins
3、在网上下载jekins的插件包，找到jekins的安装目录并且找到plungs这个文件夹，把下载好的文件放入文件夹内，这样安装会比较快
4、启动jekins
5、创建一个任务
6、配置git地址和仓库账号密码
7、设置触发器
8、构建运行环境和运行命令
9、构建完成之后可以查看分析运行结果
10、可以在构建历史中查看或者是测试日志查看脚本运行情况
11、如果用例执行失败，也可以在控制台中查看运行失败的原因

二十五、定时触发器怎么设置的？格式是什么样？
定时触发器分为 分 时 日 月 周
我们一般设置周一到周五这五个工作日，每天执行3次，分别是 早上的八点半 中午的十二点半 下午的六点半 在周一至周五开始执行
30 8,12,18 * * 1,2,3,4,5

二十六、命令行执行Python代码为什么会报错？
1、public包是人为构建的，python不能识别public包
2、selenium是python目录下lib文件夹内的，python可以识别这个目录

二十七、为什么Pycharm中执行代码不出错，而在命令执行会出错？
因为Pycharm把自己项目的根目录设为默认路径，因此Pycharm可以识别，而命令行没有默认路径，因此不能识别

二十八、项目介绍
1、项目背景--参考CRM项目和DBshop项目
    AeaiCRM客户关系管理系统是提供给XX公司销售部门使用的，用于管理客户信息和销售活动，达到提高公司业绩和规范管理销售工作的目的。软件是B/S架构的，服务器安装在CentOS7操作系统，应用服务器使用的是Tomcat，数据库用的是MySQL。软件的客户信息、线索管理、商机管理、订单管理等模块。
    下面我简单介绍下我们的测试流程。首先拿到项目后我们会熟悉项目的业务，熟悉整个软件的业务流程。然后就是产品会给我们澄清需求，我们再根据需求来设计测试思路，等产品和开发评审完思路之后，再根据测试思路来编写测试用例。开发提交了测试版本后，我们会把新的测试版本布署到测试环境上，进行冒烟测试，再执行所有的测试用例。发现Bug之后我们会用禅道来提交和跟踪Bug，我也会用抓包、看日志、调试数据等方法来定位Bug，协助开发快速修改Bug。等开发修改完Bug之后，我们会进行回归测试，不仅要验证Bug是否解决，还要测一下有没有引入新的问题。最后用例执行完了，Bug也全部关闭了，我们就会编写测试报告。